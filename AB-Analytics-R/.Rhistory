# Contar valores
cat("Número de observaciones en el conjunto de entrenamiento:", nrow(df_train), "\n")
cat("Número de observaciones en el conjunto de prueba:", nrow(df_test), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train)
summary(df_test)
# Ajuste manual del número óptimo de árboles (ntree)
df_rmse <- data.frame(ntree = integer(), rmse = numeric())
ntree_values <- seq(5, 150, by = 1)
set.seed(2706)
for (nt in ntree_values) {
rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi + region + cluster,
data = df_train,
ntree = nt,
mtry = 2,
nodesize = 5)
pred_temp <- predict(rf_model_temp, df_test)
rmse_temp <- sqrt(mean((df_test$inflacion - pred_temp)^2))
# Guardar el RMSE
df_rmse <- rbind(df_rmse, data.frame(ntree = nt, rmse = rmse_temp))
}
df_rmse <- df_rmse %>% arrange(rmse)
head(df_rmse, 5)
# Gráfico de MSE vs ntree
plot <- ggplot(df_rmse, aes(x = ntree, y = rmse)) +
geom_line(color = "#4400a4") +
geom_point(color = "#4400a4", size=0.6) +
geom_area(fill = "#4400a4", alpha = 0.2) +
coord_cartesian(ylim = c( min(df_rmse$rmse), max(df_rmse$rmse))) +
labs(title = "RMSE vs Número de Árboles",
x = "Número de Árboles",
y = "RMSE")
ggplotly(plot)
posibles_arboles <- df_rmse %>% head(5) %>% arrange(ntree)
arboles_optimos <- posibles_arboles[1, "ntree"]
cat("Número óptimo de árboles:", arboles_optimos, "\n")
set.seed(2706)
# Ajustar el modelo con el número óptimo de árboles
rf_model_opt <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi + cluster + region,
data = df_train,
ntree = arboles_optimos,
mtry = 2,
nodesize = 5)
# Resumen del modelo
print(rf_model_opt)
# Predecir la inflación en el conjunto de prueba
predicciones_opt <- predict(rf_model_opt, df_test)
# Evaluar el rendimiento del modelo optimizado (ejemplo con RMSE)
rmse_opt <-sqrt(mean((df_test$inflacion - predicciones_opt)^2))
cat("RMSE del modelo optimizado:", rmse_opt, "\n")
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(real = df_test$inflacion, prediccion = predicciones_opt, error_porcentual = (df_test$inflacion - predicciones_opt) / df_test$inflacion * 100)
plot <- ggplot(df_pred, aes(x = real, y = prediccion)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, max(df_pred$real)) +
xlim(0, max(df_pred$real)) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
ggplotly(plot)
# Countplot error porcentual
df_pred$error_porcentual <- round(df_pred$error_porcentual, 2)
df_pred$error_porcentual <- ifelse(df_pred$error_porcentual < 0, df_pred$error_porcentual * -1, df_pred$error_porcentual)
df_pred$error_porcentual <- ifelse(df_pred$error_porcentual > 200, 200, df_pred$error_porcentual)
plot <- ggplot(df_pred, aes(x = error_porcentual)) +
geom_density(fill = "#4400a4", alpha= 0.8) +
labs(title = "Distribución del Error Porcentual",
x = "Error Porcentual",
y = "Frecuencia")
ggplotly(plot)
# Importancia de las variables usando IncNodePurity
importancia <- importance(rf_model_opt)
importancia_df <- data.frame(variable = rownames(importancia),
importancia = importancia[, "IncNodePurity"])
# Ordena las variables por importancia
importancia_df <- importancia_df[order(importancia_df$importancia, decreasing = TRUE),]
plot <- ggplot(importancia_df, aes(x = reorder(variable, importancia), y = importancia, fill=variable)) +
geom_bar(stat = "identity" ) +
coord_flip() +
scale_fill_manual(values = c("#339aff", "#184d80", "#1e63a7", "#133d66", "#297bcb","#0f3051")) +
labs(title = "Importancia de las Variables",
x = "",
y = "Incremento en Pureza del Nodo") +
theme(legend.position = "none")
plot <- ggplotly(plot) %>% layout(xaxis = list(range = c(0, 4500)))
plot
# Dividir df_limpio en train y test
set.seed(2706)
df_limpio_1 <- df_limpio %>% filter(inflacion < 7)
df_limpio_2 <- df_limpio %>% filter(inflacion >= 7)
train_index_1 <- createDataPartition(1:nrow(df_limpio_1), p = .8, list = FALSE)
train_index_2 <- createDataPartition(1:nrow(df_limpio_2), p = .8, list = FALSE)
df_train_1 <- df_limpio_1[train_index_1, ]
df_test_1 <- df_limpio_1[-train_index_1, ]
df_train_2 <- df_limpio_2[train_index_2, ]
df_test_2 <- df_limpio_2[-train_index_2, ]
# Contar valores
cat("Número de observaciones en el conjunto de entrenamiento 1:", nrow(df_train_1), "\n")
cat("Número de observaciones en el conjunto de prueba 1:", nrow(df_test_1), "\n")
cat("Número de observaciones en el conjunto de entrenamiento 2:", nrow(df_train_2), "\n")
cat("Número de observaciones en el conjunto de prueba 2:", nrow(df_test_2), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train_1)
summary(df_test_1)
summary(df_train_2)
summary(df_test_2)
# Ajuste manual del número óptimo de árboles (ntree)
df_rmse_1 <- data.frame(ntree = integer(), rmse = numeric())
df_rmse_2 <- data.frame(ntree = integer(), rmse = numeric())
ntree_values <- seq(5, 150, by = 1)
set.seed(2706)
for (nt in ntree_values) {
rf_model_temp_1 <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi + region + cluster,
data = df_train_1,
ntree = nt,
mtry = 2,
nodesize = 5)
pred_temp_1 <- predict(rf_model_temp_1, df_test_1)
rmse_temp_1 <- sqrt(mean((df_test_1$inflacion - pred_temp)^2))
# Guardar el RMSE
df_rmse_1 <- rbind(df_rmse_1, data.frame(ntree = nt, rmse = rmse_temp))
}
set.seed(2706)
for (nt in ntree_values) {
rf_model_temp_1 <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi + region + cluster,
data = df_train_1,
ntree = nt,
mtry = 2,
nodesize = 5)
pred_temp_1 <- predict(rf_model_temp_1, df_test_1)
rmse_temp_1 <- sqrt(mean((df_test_1$inflacion - pred_temp_1)^2))
# Guardar el RMSE
df_rmse_1 <- rbind(df_rmse_1, data.frame(ntree = nt, rmse = rmse_temp_1))
}
df_rmse_1 <- df_rmse_1 %>% arrange(rmse)
head(df_rmse_1, 5)
set.seed(2706)
for (nt in ntree_values) {
rf_model_temp_2 <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi + region + cluster,
data = df_train_2,
ntree = nt,
mtry = 2,
nodesize = 5)
pred_temp_2 <- predict(rf_model_temp_2, df_test_2)
rmse_temp_2 <- sqrt(mean((df_test_2$inflacion - pred_temp_2)^2))
# Guardar el RMSE
df_rmse_2 <- rbind(df_rmse_2, data.frame(ntree = nt, rmse = rmse_temp_2))
}
df_rmse_2 <- df_rmse_2 %>% arrange(rmse)
head(df_rmse_2, 5)
# Gráfico de RMSE vs ntree
plot_1 <- ggplot(df_rmse_1, aes(x = ntree, y = rmse)) +
geom_line(color = "#4400a4") +
geom_point(color = "#4400a4", size=0.6) +
geom_area(fill = "#4400a4", alpha = 0.2) +
coord_cartesian(ylim = c( min(df_rmse_1$rmse), max(df_rmse_1$rmse))) +
labs(title = "RMSE vs Número de Árboles",
x = "Número de Árboles",
y = "RMSE")
ggplotly(plot_1)
# Gráfico de RMSE vs ntree
plot_2 <- ggplot(df_rmse_2, aes(x = ntree, y = rmse)) +
geom_line(color = "#4400a4") +
geom_point(color = "#4400a4", size=0.6) +
geom_area(fill = "#4400a4", alpha = 0.2) +
coord_cartesian(ylim = c( min(df_rmse_2$rmse), max(df_rmse_2$rmse))) +
labs(title = "RMSE vs Número de Árboles",
x = "Número de Árboles",
y = "RMSE")
ggplotly(plot_2)
posibles_arboles_1 <- df_rmse_1 %>% head(5) %>% arrange(ntree)
posibles_arboles_2 <- df_rmse_2 %>% head(5) %>% arrange(ntree)
arboles_optimos_1 <- posibles_arboles_1[1, "ntree"]
arboles_optimos_2 <- posibles_arboles_2[1, "ntree"]
cat("Número óptimo de árboles:", arboles_optimos_1, "\n")
cat("Número óptimo de árboles:", arboles_optimos_2, "\n")
set.seed(2706)
# Ajustar el modelo con el número óptimo de árboles
rf_model_opt_1 <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi + cluster + region,
data = df_train_1,
ntree = arboles_optimos_1,
mtry = 2,
nodesize = 5)
# Resumen del modelo
print(rf_model_opt_1)
rf_model_opt_2 <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi + cluster + region,
data = df_train_2,
ntree = arboles_optimos_2,
mtry = 2,
nodesize = 5)
print(rf_model_opt_2)
# Predecir la inflación en el conjunto de prueba
predicciones_opt_1 <- predict(rf_model_opt_1, df_test_1)
predicciones_opt_2 <- predict(rf_model_opt_2, df_test_2)
# Evaluar el rendimiento del modelo optimizado (ejemplo con RMSE)
rmse_opt_1 <-sqrt(mean((df_test_1$inflacion - predicciones_opt_1)^2))
rmse_opt_2 <-sqrt(mean((df_test_2$inflacion - predicciones_opt_2)^2))
cat("RMSE del modelo optimizado:", rmse_opt_1, "\n")
cat("RMSE del modelo optimizado:", rmse_opt_2, "\n")
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(RColorBrewer)
library(ggcorrplot)
library(readxl)
library(plotly)
library(scales)
library(reshape2)
library(corrplot)
library(stringdist)
library(randomForest)
library(caret)
library(factoextra)
inflacion <- read_excel("datasets/imf-dm-export-inflacion.xlsx")
head(inflacion[0:2])
pib <- read_excel("datasets/imf-dm-export-pib.xls")
head(pib[0:2])
ingreso_fiscal <- read_excel("datasets/imf-dm-export-presion-fiscal.xls")
head(ingreso_fiscal[0:2])
pib_per_capita <- read_excel("datasets/imf-dm-export-pib-per-capita.xls")
head(pib_per_capita[0:2])
formatear_fmi <- function(df, valor) {
# Contar los datos nulos
df <- df %>% replace(df == "no data", NA)
print(paste("Total Nulos:", sum(is.na(df))))
# Eliminar los datos nulos
df <- df %>% drop_na()
# Seleccionar las columnas de los años
años <- colnames(df)[-1]
# Cambiar el nombre de la columna de país
colnames(df)[1] <- "pais"
# Convertir las columnas a valores numéricos
df <- df %>% mutate_at(vars(-pais), as.numeric)
# Transformar el DataFrame de formato ancho a formato largo
df <- df %>% pivot_longer(cols = all_of(años)
, names_to ="año",
values_to = valor) %>%
mutate(across(c(valor, año), as.numeric))
# Mostrar los primeros registros y el resumen de los datos
print("Primeros Registros:")
print(head(df))
print("Resumen de los Datos:")
print(summary(df))
return(df)
}
inflacion <- formatear_fmi(inflacion, "inflacion")
pib <- formatear_fmi(pib, "pib")
ingreso_fiscal <- formatear_fmi(ingreso_fiscal, "ingreso_fiscal")
pib_per_capita <- formatear_fmi(pib_per_capita, "pib_per_capita")
fmi <- pib %>%
full_join(ingreso_fiscal, by = c("pais", "año")) %>%
full_join(pib_per_capita, by = c("pais", "año")) %>%
full_join(inflacion, by = c("pais", "año"))
fmi <- fmi %>% filter(año >= 1995 & año <= 2023)
cpi <- read.csv("datasets/cpi/CPI-Archive-2011.csv")[c(1,3,4)]
colnames(cpi) <- c("pais","region","score")
for (año in 2010:1995) {
# Importar los datos del CPI
cpi_año <- read.csv(paste0("datasets/cpi/CPI-Archive-",año,".csv"))[c(1,3,4)]
# Cambiar el nombre de la columna de país
colnames(cpi_año)[1] <- "pais"
colnames(cpi_año)[2] <- "region"
# Unir los datos del CPI
cpi <- cpi %>%
left_join(cpi_año, by = c("pais","region"), suffix = c("", año))
}
colnames(cpi)[3] <- "score2011"
# Convertir las columnas a numérico por error al pivotar
cpi <- cpi %>% mutate(across(starts_with("score"), as.numeric))
cpi <- cpi %>% pivot_longer( cols = starts_with("score"), names_to = "año", names_prefix = "score", values_to = "cpi") %>%
mutate(año = as.numeric(año))
# Ajustar la escala
cpi$cpi <- cpi$cpi * 10
# Importar el resto de años
cpi_2012_2022 <- read_excel("datasets/cpi/CPI-Archive-2012-2023.xlsx")[c(1,3,4,5)]
# Cambiar el nombre de las columnas
colnames(cpi_2012_2022) <- c("pais","año","region","cpi")
# Pasar a numérico
cpi_2012_2022 <- cpi_2012_2022 %>% mutate(cpi = as.numeric(cpi),
año = as.numeric(año))
# Unir los datos del CPI verticalmente
cpi <- rbind(cpi, cpi_2012_2022)
cpi <- cpi %>% mutate(region = as.factor(region))
fmi$pais <- recode(fmi$pais,
"Korea, Republic of" = "Korea (South)",
"China, People's Republic of" = "China",
"Congo, Dem. Rep. of the" = "Congo",
"Taiwan Province of China" = "Taiwan",
"Australia and New Zealand" = "Australia",
"São Tomé and Príncipe" = "Sao Tome and Principe",
"Gambia, The" = "Gambia",
"Bahamas, The" = "Bahamas",
"Congo, Republic of" = "Congo Republic",
"Hong Kong SAR" = "Hong Kong")
# Calcula la distancia de similitud entre los nombres de los países
distancias <- stringdistmatrix(fmi$pais, cpi$pais, method = "jw")
indices <- apply(distancias, 1, which.min)
nombres_equivalentes <- cpi$pais[indices]
# Calcula el porcentaje de error estimado
porcentaje_error <- apply(distancias, 1, min)
porcentaje_error <- porcentaje_error * 100
# Añadir el porcentaje de error estimado al dataframe original
fmi <- fmi %>%
mutate(porcentaje_error = porcentaje_error,
nombre_eq = nombres_equivalentes)
fmi %>% select(pais, nombre_eq, porcentaje_error) %>%  group_by(pais) %>% slice(1) %>% arrange(desc(porcentaje_error))
fmi <- fmi %>% ungroup() %>% filter(porcentaje_error == 0)
fmi$pais <- fmi$nombre_eq
fmi <- fmi %>% select(-nombre_eq, -porcentaje_error) %>%
mutate(año = as.numeric(año))
df <- cpi %>%
full_join(fmi, by = c("pais", "año"))
df <- df %>% arrange(pais, año)
df <- df[rowSums(is.na(df)) < 4, ]
summary(df)
head(df)
# Pasar el dataframe a formato largo
df_long <- df %>%
select(-pais, -region) %>%
pivot_longer(cols = -año, names_to = "variable", values_to = "valor") %>%
group_by(año, variable) %>%
summarize(n_nulos = sum(is.na(valor)), .groups = "drop")
# Crear el gráfico con ggplot2
nulos_año_plot <- ggplot(df_long, aes(x = año, y = n_nulos, fill = variable )) +
geom_bar(stat = "identity", width = 0.9, color="#aaa") +
facet_wrap(~variable, scales = "free") +
labs(
title = "Cantidad de Nulos por Año y Variable",
x = "Año",
y = "Cantidad de Nulos"
) +
theme(legend.position = "none",
panel.spacing.x = unit(2, "lines"),
panel.spacing.y = unit(4, "lines"))
ggplotly(nulos_año_plot)
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(RColorBrewer)
library(ggcorrplot)
library(readxl)
library(plotly)
library(scales)
library(reshape2)
library(corrplot)
library(stringdist)
library(randomForest)
library(caret)
library(factoextra)
inflacion <- read_excel("datasets/imf-dm-export-inflacion.xlsx")
head(inflacion[0:2])
pib <- read_excel("datasets/imf-dm-export-pib.xls")
head(pib[0:2])
ingreso_fiscal <- read_excel("datasets/imf-dm-export-presion-fiscal.xls")
head(ingreso_fiscal[0:2])
pib_per_capita <- read_excel("datasets/imf-dm-export-pib-per-capita.xls")
head(pib_per_capita[0:2])
formatear_fmi <- function(df, valor) {
# Contar los datos nulos
df <- df %>% replace(df == "no data", NA)
print(paste("Total Nulos:", sum(is.na(df))))
# Eliminar los datos nulos
df <- df %>% drop_na()
# Seleccionar las columnas de los años
años <- colnames(df)[-1]
# Cambiar el nombre de la columna de país
colnames(df)[1] <- "pais"
# Convertir las columnas a valores numéricos
df <- df %>% mutate_at(vars(-pais), as.numeric)
# Transformar el DataFrame de formato ancho a formato largo
df <- df %>% pivot_longer(cols = all_of(años)
, names_to ="año",
values_to = valor) %>%
mutate(across(c(valor, año), as.numeric))
# Mostrar los primeros registros y el resumen de los datos
print("Primeros Registros:")
print(head(df))
print("Resumen de los Datos:")
print(summary(df))
return(df)
}
inflacion <- formatear_fmi(inflacion, "inflacion")
pib <- formatear_fmi(pib, "pib")
ingreso_fiscal <- formatear_fmi(ingreso_fiscal, "ingreso_fiscal")
pib_per_capita <- formatear_fmi(pib_per_capita, "pib_per_capita")
fmi <- pib %>%
full_join(ingreso_fiscal, by = c("pais", "año")) %>%
full_join(pib_per_capita, by = c("pais", "año")) %>%
full_join(inflacion, by = c("pais", "año"))
fmi <- fmi %>% filter(año >= 1995 & año <= 2023)
cpi <- read.csv("datasets/cpi/CPI-Archive-2011.csv")[c(1,3,4)]
colnames(cpi) <- c("pais","region","score")
for (año in 2010:1995) {
# Importar los datos del CPI
cpi_año <- read.csv(paste0("datasets/cpi/CPI-Archive-",año,".csv"))[c(1,3,4)]
# Cambiar el nombre de la columna de país
colnames(cpi_año)[1] <- "pais"
colnames(cpi_año)[2] <- "region"
# Unir los datos del CPI
cpi <- cpi %>%
left_join(cpi_año, by = c("pais","region"), suffix = c("", año))
}
colnames(cpi)[3] <- "score2011"
# Convertir las columnas a numérico por error al pivotar
cpi <- cpi %>% mutate(across(starts_with("score"), as.numeric))
cpi <- cpi %>% pivot_longer( cols = starts_with("score"), names_to = "año", names_prefix = "score", values_to = "cpi") %>%
mutate(año = as.numeric(año))
# Ajustar la escala
cpi$cpi <- cpi$cpi * 10
# Importar el resto de años
cpi_2012_2022 <- read_excel("datasets/cpi/CPI-Archive-2012-2023.xlsx")[c(1,3,4,5)]
# Cambiar el nombre de las columnas
colnames(cpi_2012_2022) <- c("pais","año","region","cpi")
# Pasar a numérico
cpi_2012_2022 <- cpi_2012_2022 %>% mutate(cpi = as.numeric(cpi),
año = as.numeric(año))
# Unir los datos del CPI verticalmente
cpi <- rbind(cpi, cpi_2012_2022)
cpi <- cpi %>% mutate(region = as.factor(region))
fmi$pais <- recode(fmi$pais,
"Korea, Republic of" = "Korea (South)",
"China, People's Republic of" = "China",
"Congo, Dem. Rep. of the" = "Congo",
"Taiwan Province of China" = "Taiwan",
"Australia and New Zealand" = "Australia",
"São Tomé and Príncipe" = "Sao Tome and Principe",
"Gambia, The" = "Gambia",
"Bahamas, The" = "Bahamas",
"Congo, Republic of" = "Congo Republic",
"Hong Kong SAR" = "Hong Kong")
# Calcula la distancia de similitud entre los nombres de los países
distancias <- stringdistmatrix(fmi$pais, cpi$pais, method = "jw")
indices <- apply(distancias, 1, which.min)
nombres_equivalentes <- cpi$pais[indices]
# Calcula el porcentaje de error estimado
porcentaje_error <- apply(distancias, 1, min)
porcentaje_error <- porcentaje_error * 100
# Añadir el porcentaje de error estimado al dataframe original
fmi <- fmi %>%
mutate(porcentaje_error = porcentaje_error,
nombre_eq = nombres_equivalentes)
fmi %>% select(pais, nombre_eq, porcentaje_error) %>%  group_by(pais) %>% slice(1) %>% arrange(desc(porcentaje_error))
fmi <- fmi %>% ungroup() %>% filter(porcentaje_error == 0)
fmi$pais <- fmi$nombre_eq
fmi <- fmi %>% select(-nombre_eq, -porcentaje_error) %>%
mutate(año = as.numeric(año))
df <- cpi %>%
full_join(fmi, by = c("pais", "año"))
df <- df %>% arrange(pais, año)
df <- df[rowSums(is.na(df)) < 4, ]
summary(df)
head(df)
# Pasar el dataframe a formato largo
df_long <- df %>%
select(-pais, -region) %>%
pivot_longer(cols = -año, names_to = "variable", values_to = "valor") %>%
group_by(año, variable) %>%
summarize(n_nulos = sum(is.na(valor)), .groups = "drop")
# Crear el gráfico con ggplot2
nulos_año_plot <- ggplot(df_long, aes(x = año, y = n_nulos, fill = variable )) +
geom_bar(stat = "identity", width = 0.9, color="#aaa") +
facet_wrap(~variable, scales = "free") +
labs(
title = "Cantidad de Nulos por Año y Variable",
x = "Año",
y = "Cantidad de Nulos"
) +
theme(legend.position = "none",
panel.spacing.x = unit(2, "lines"),
panel.spacing.y = unit(4, "lines"))
ggplotly(nulos_año_plot)
# Pasar el dataframe a formato largo
df_long <- df %>%
select(-pais, -region) %>%
pivot_longer(cols = -año, names_to = "variable", values_to = "valor") %>%
group_by(año, variable) %>%
summarize(n_nulos = sum(is.na(valor)), .groups = "drop")
# Crear el gráfico con ggplot2
nulos_año_plot <- ggplot(df_long, aes(x = año, y = n_nulos, fill = variable )) +
geom_bar(stat = "identity", width = 0.9, color="#aaa") +
facet_wrap(~variable, scales = "free") +
labs(
title = "Cantidad de Nulos por Año y Variable",
x = "Año",
y = "Cantidad de Nulos"
) +
theme(legend.position = "none",
panel.spacing.x = unit(2, "lines"),
panel.spacing.y = unit(4, "lines"))
ggplotly(nulos_año_plot)
# Pasar el dataframe a formato largo
df_long <- df %>%
select(-pais, -region) %>%
pivot_longer(cols = -año, names_to = "variable", values_to = "valor") %>%
group_by(año, variable) %>%
summarize(n_nulos = sum(is.na(valor)), .groups = "drop")
# Crear el gráfico con ggplot2
nulos_año_plot <- ggplot(df_long, aes(x = año, y = n_nulos, fill = variable )) +
geom_bar(stat = "identity", width = 0.9, color="#aaaaaa") +
facet_wrap(~variable, scales = "free") +
labs(
title = "Cantidad de Nulos por Año y Variable",
x = "Año",
y = "Cantidad de Nulos"
) +
theme(legend.position = "none",
panel.spacing.x = unit(2, "lines"),
panel.spacing.y = unit(4, "lines"))
ggplotly(nulos_año_plot)
