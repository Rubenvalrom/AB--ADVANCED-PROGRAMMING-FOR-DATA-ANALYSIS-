summary(df_train)
summary(df_test)
# Dividir df_limpio en train y test
set.seed(2706)
train_index <- createDataPartition(1:nrow(df_limpio), p = .8, list = FALSE)
df_train <- df_limpio[train_index, ]
df_test <- df_limpio[-train_index, ]
# Contar valores
cat("Número de observaciones en el conjunto de entrenamiento:", nrow(df_train), "\n")
cat("Número de observaciones en el conjunto de prueba:", nrow(df_test), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train)
summary(df_test)
# Ajuste manual del número óptimo de árboles (ntree)
df_mse <- data.frame(ntree = integer(), mse = numeric())
ntree_values <- seq(80, 150, by = 1)
# Ajuste manual del número óptimo de árboles (ntree)
df_mse <- data.frame(ntree = integer(), mse = numeric())
ntree_values <- seq(5, 150, by = 1)
for (nt in ntree_values) {
rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = nt,
mtry = 3)
pred_temp <- predict(rf_model_temp, df_test)
mse_temp <- mean((df_test$inflacion - pred_temp)^2)
# Guardar el RMSE
df_mse <- rbind(df_mse, data.frame(ntree = nt, mse = mse_temp))
}
head(df_mse %>%
arrange(mse))
# Gráfico de MSE vs ntree
plot <- ggplot(df_mse, aes(x = ntree, y = mse)) +
geom_line(color = "#4400a4") +
geom_point(color = "#4400a4", size=0.6) +
geom_area(fill = "#4400a4", alpha = 0.2) +
labs(title = "MSE vs Número de Árboles",
x = "Número de Árboles",
y = "MSE")
ggplotly(plot)
# Obtener el ntree con el menor RMSE
arboles_optimos <- df_mse[which.min(df_mse$mse), "ntree"]
cat("Número óptimo de árboles:", arboles_optimos, "\n")
# Ajustar el modelo con el número óptimo de árboles
rf_model_opt <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = arboles_optimos,
mtry = 3)
# Resumen del modelo
print(rf_model_opt)
# Importancia de las variables usando IncNodePurity
importancia <- importance(rf_model_opt)
importancia_df <- data.frame(Variable = rownames(importancia),
Importancia = importancia[, "IncNodePurity"])
# Ordena las variables por importancia
importancia_df <- importancia_df[order(importancia_df$Importancia, decreasing = TRUE),]
plot <- ggplot(importancia_df, aes(x = reorder(Variable, Importancia), y = Importancia)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Importancia de las Variables",
x = "",
y = "Incremento en Pureza del Nodo")
ggplotly(plot)
# Predecir la inflación en el conjunto de prueba
predicciones_opt <- predict(rf_model_opt, df_test)
# Evaluar el rendimiento del modelo optimizado (ejemplo con RMSE)
mse_opt <-mean((df_test$inflacion - predicciones_opt)^2)
cat("MSE del modelo optimizado:", mse_opt, "\n")
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, 100) +
xlim(0, 100) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
ggplotly(plot)
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0,) +
xlim(0,) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, max(Predicción)) +
xlim(0, max(Real)) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, max(df_pred$Predicción)) +
xlim(0, max(df_pred$Real)) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
ggplotly(plot)
df_limpio <- df %>% select(-pais, -año) %>%
drop_na() %>%
filter(inflacion < 20)
# Dividir df_limpio en train y test
set.seed(2706)
train_index <- createDataPartition(1:nrow(df_limpio), p = .8, list = FALSE)
df_train <- df_limpio[train_index, ]
df_test <- df_limpio[-train_index, ]
# Contar valores
cat("Número de observaciones en el conjunto de entrenamiento:", nrow(df_train), "\n")
cat("Número de observaciones en el conjunto de prueba:", nrow(df_test), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train)
summary(df_test)
# Ajuste manual del número óptimo de árboles (ntree)
df_mse <- data.frame(ntree = integer(), mse = numeric())
ntree_values <- seq(5, 150, by = 1)
for (nt in ntree_values) {
rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = nt,
mtry = 3)
pred_temp <- predict(rf_model_temp, df_test)
mse_temp <- mean((df_test$inflacion - pred_temp)^2)
# Guardar el RMSE
df_mse <- rbind(df_mse, data.frame(ntree = nt, mse = mse_temp))
}
head(df_mse %>%
arrange(mse))
# Gráfico de MSE vs ntree
plot <- ggplot(df_mse, aes(x = ntree, y = mse)) +
geom_line(color = "#4400a4") +
geom_point(color = "#4400a4", size=0.6) +
geom_area(fill = "#4400a4", alpha = 0.2) +
labs(title = "MSE vs Número de Árboles",
x = "Número de Árboles",
y = "MSE")
ggplotly(plot)
# Obtener el ntree con el menor RMSE
arboles_optimos <- df_mse[which.min(df_mse$mse), "ntree"]
cat("Número óptimo de árboles:", arboles_optimos, "\n")
# Ajustar el modelo con el número óptimo de árboles
rf_model_opt <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = arboles_optimos,
mtry = 3)
# Resumen del modelo
print(rf_model_opt)
# Importancia de las variables usando IncNodePurity
importancia <- importance(rf_model_opt)
importancia_df <- data.frame(Variable = rownames(importancia),
Importancia = importancia[, "IncNodePurity"])
# Ordena las variables por importancia
importancia_df <- importancia_df[order(importancia_df$Importancia, decreasing = TRUE),]
plot <- ggplot(importancia_df, aes(x = reorder(Variable, Importancia), y = Importancia)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Importancia de las Variables",
x = "",
y = "Incremento en Pureza del Nodo")
ggplotly(plot)
# Predecir la inflación en el conjunto de prueba
predicciones_opt <- predict(rf_model_opt, df_test)
# Evaluar el rendimiento del modelo optimizado (ejemplo con RMSE)
mse_opt <-mean((df_test$inflacion - predicciones_opt)^2)
cat("MSE del modelo optimizado:", mse_opt, "\n")
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, max(df_pred$Predicción)) +
xlim(0, max(df_pred$Real)) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
ggplotly(plot)
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, max(df_pred$Real)) +
xlim(0, max(df_pred$Real)) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
ggplotly(plot)
df_limpio <- df %>% select(-pais, -año) %>%
drop_na() %>%
filter(inflacion < quantile(inflacion, 0.95))
# Dividir df_limpio en train y test
set.seed(2706)
train_index <- createDataPartition(1:nrow(df_limpio), p = .8, list = FALSE)
df_train <- df_limpio[train_index, ]
df_test <- df_limpio[-train_index, ]
# Contar valores
cat("Número de observaciones en el conjunto de entrenamiento:", nrow(df_train), "\n")
cat("Número de observaciones en el conjunto de prueba:", nrow(df_test), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train)
summary(df_test)
df_limpio <- df %>% select(-pais, -año) %>%
drop_na() %>%
filter(inflacion < quantile(inflacion, 0.9))
# Dividir df_limpio en train y test
set.seed(2706)
train_index <- createDataPartition(1:nrow(df_limpio), p = .8, list = FALSE)
df_train <- df_limpio[train_index, ]
df_test <- df_limpio[-train_index, ]
# Contar valores
cat("Número de observaciones en el conjunto de entrenamiento:", nrow(df_train), "\n")
cat("Número de observaciones en el conjunto de prueba:", nrow(df_test), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train)
summary(df_test)
df_limpio <- df %>% select(-pais, -año) %>%
drop_na() %>%
filter(inflacion < quantile(inflacion, 0.95))
# Dividir df_limpio en train y test
set.seed(2706)
train_index <- createDataPartition(1:nrow(df_limpio), p = .8, list = FALSE)
df_train <- df_limpio[train_index, ]
df_test <- df_limpio[-train_index, ]
# Contar valores
cat("Número de observaciones en el conjunto de entrenamiento:", nrow(df_train), "\n")
cat("Número de observaciones en el conjunto de prueba:", nrow(df_test), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train)
summary(df_test)
# Ajuste manual del número óptimo de árboles (ntree)
df_mse <- data.frame(ntree = integer(), mse = numeric())
ntree_values <- seq(5, 150, by = 1)
for (nt in ntree_values) {
rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = nt,
mtry = 3)
pred_temp <- predict(rf_model_temp, df_test)
mse_temp <- mean((df_test$inflacion - pred_temp)^2)
# Guardar el RMSE
df_mse <- rbind(df_mse, data.frame(ntree = nt, mse = mse_temp))
}
head(df_mse %>%
arrange(mse))
# Gráfico de MSE vs ntree
plot <- ggplot(df_mse, aes(x = ntree, y = mse)) +
geom_line(color = "#4400a4") +
geom_point(color = "#4400a4", size=0.6) +
geom_area(fill = "#4400a4", alpha = 0.2) +
labs(title = "MSE vs Número de Árboles",
x = "Número de Árboles",
y = "MSE")
ggplotly(plot)
# Obtener el ntree con el menor RMSE
arboles_optimos <- df_mse[which.min(df_mse$mse), "ntree"]
cat("Número óptimo de árboles:", arboles_optimos, "\n")
# Ajustar el modelo con el número óptimo de árboles
rf_model_opt <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = arboles_optimos,
mtry = 3)
# Resumen del modelo
print(rf_model_opt)
# Importancia de las variables usando IncNodePurity
importancia <- importance(rf_model_opt)
importancia_df <- data.frame(Variable = rownames(importancia),
Importancia = importancia[, "IncNodePurity"])
# Ordena las variables por importancia
importancia_df <- importancia_df[order(importancia_df$Importancia, decreasing = TRUE),]
plot <- ggplot(importancia_df, aes(x = reorder(Variable, Importancia), y = Importancia)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Importancia de las Variables",
x = "",
y = "Incremento en Pureza del Nodo")
ggplotly(plot)
# Predecir la inflación en el conjunto de prueba
predicciones_opt <- predict(rf_model_opt, df_test)
# Evaluar el rendimiento del modelo optimizado (ejemplo con RMSE)
mse_opt <-mean((df_test$inflacion - predicciones_opt)^2)
cat("MSE del modelo optimizado:", mse_opt, "\n")
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, max(df_pred$Real)) +
xlim(0, max(df_pred$Real)) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
ggplotly(plot)
df_limpio <- df %>% select(-pais, -año) %>%
drop_na() %>%
filter(inflacion < quantile(inflacion, 0.95))
# Dividir df_limpio en train y test
set.seed(2706)
train_index <- createDataPartition(1:nrow(df_limpio), p = .8, list = FALSE)
df_train <- df_limpio[train_index, ]
df_test <- df_limpio[-train_index, ]
# Contar valores
cat("Número de observaciones en el conjunto de entrenamiento:", nrow(df_train), "\n")
cat("Número de observaciones en el conjunto de prueba:", nrow(df_test), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train)
summary(df_test)
# Ajuste manual del número óptimo de árboles (ntree)
df_rmse <- data.frame(ntree = integer(), rmse = numeric())
ntree_values <- seq(5, 150, by = 1)
for (nt in ntree_values) {
rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = nt,
mtry = 3)
pred_temp <- predict(rf_model_temp, df_test)
rmse_temp <- sqrt(mean((df_test$inflacion - pred_temp)^2))
# Guardar el RMSE
df_rmse <- rbind(df_rmse, data.frame(ntree = nt, rmse = mse_temp))
}
head(df_mse %>% arrange(rmse))
for (nt in ntree_values) {
rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = nt,
mtry = 3)
pred_temp <- predict(rf_model_temp, df_test)
rmse_temp <- sqrt(mean((df_test$inflacion - pred_temp)^2))
# Guardar el RMSE
df_rmse <- rbind(df_rmse, data.frame(ntree = nt, rmse = rmse_temp))
}
head(df_mse %>% arrange(rmse))
# Ajuste manual del número óptimo de árboles (ntree)
df_rmse <- data.frame(ntree = integer(), rmse = numeric())
ntree_values <- seq(5, 150, by = 1)
for (nt in ntree_values) {
rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = nt,
mtry = 3)
pred_temp <- predict(rf_model_temp, df_test)
rmse_temp <- sqrt(mean((df_test$inflacion - pred_temp)^2))
# Guardar el RMSE
df_rmse <- rbind(df_rmse, data.frame(ntree = nt, rmse = rmse_temp))
}
for (nt in ntree_values) {
rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = nt,
mtry = 3)
pred_temp <- predict(rf_model_temp, df_test)
rmse_temp <- sqrt(mean((df_test$inflacion - pred_temp)^2))
# Guardar el RMSE
df_rmse <- rbind(df_rmse, data.frame(ntree = nt, rmse = rmse_temp))
}
head(df_rmse %>% arrange(rmse))
# Gráfico de MSE vs ntree
plot <- ggplot(df_mse, aes(x = ntree, y = mse)) +
geom_line(color = "#4400a4") +
geom_point(color = "#4400a4", size=0.6) +
geom_area(fill = "#4400a4", alpha = 0.2) +
labs(title = "RMSE vs Número de Árboles",
x = "Número de Árboles",
y = "RMSE")
ggplotly(plot)
# Gráfico de MSE vs ntree
plot <- ggplot(df_mse, aes(x = ntree, y = rmse)) +
geom_line(color = "#4400a4") +
geom_point(color = "#4400a4", size=0.6) +
geom_area(fill = "#4400a4", alpha = 0.2) +
labs(title = "RMSE vs Número de Árboles",
x = "Número de Árboles",
y = "RMSE")
ggplotly(plot)
# Gráfico de MSE vs ntree
plot <- ggplot(df_rmse, aes(x = ntree, y = rmse)) +
geom_line(color = "#4400a4") +
geom_point(color = "#4400a4", size=0.6) +
geom_area(fill = "#4400a4", alpha = 0.2) +
labs(title = "RMSE vs Número de Árboles",
x = "Número de Árboles",
y = "RMSE")
ggplotly(plot)
# Obtener el ntree con el menor RMSE
arboles_optimos <- df_rmse[which.min(df_rmse$rmse), "ntree"]
cat("Número óptimo de árboles:", arboles_optimos, "\n")
# Ajustar el modelo con el número óptimo de árboles
rf_model_opt <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = arboles_optimos,
mtry = 3)
# Resumen del modelo
print(rf_model_opt)
# Importancia de las variables usando IncNodePurity
importancia <- importance(rf_model_opt)
importancia_df <- data.frame(Variable = rownames(importancia),
Importancia = importancia[, "IncNodePurity"])
# Ordena las variables por importancia
importancia_df <- importancia_df[order(importancia_df$Importancia, decreasing = TRUE),]
plot <- ggplot(importancia_df, aes(x = reorder(Variable, Importancia), y = Importancia)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Importancia de las Variables",
x = "",
y = "Incremento en Pureza del Nodo")
ggplotly(plot)
# Predecir la inflación en el conjunto de prueba
predicciones_opt <- predict(rf_model_opt, df_test)
# Evaluar el rendimiento del modelo optimizado (ejemplo con RMSE)
rmse_opt <-sqrt(mean((df_test$inflacion - predicciones_opt)^2))
cat("RMSE del modelo optimizado:", rmse_opt, "\n")
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, max(df_pred$Real)) +
xlim(0, max(df_pred$Real)) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
ggplotly(plot)
df_limpio <- df %>% select(-pais, -año) %>%
drop_na() %>%
filter(inflacion < quantile(inflacion, 0.9))
# Dividir df_limpio en train y test
set.seed(2706)
train_index <- createDataPartition(1:nrow(df_limpio), p = .8, list = FALSE)
df_train <- df_limpio[train_index, ]
df_test <- df_limpio[-train_index, ]
# Contar valores
cat("Número de observaciones en el conjunto de entrenamiento:", nrow(df_train), "\n")
cat("Número de observaciones en el conjunto de prueba:", nrow(df_test), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train)
summary(df_test)
for (nt in ntree_values) {
rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = nt,
mtry = 3)
pred_temp <- predict(rf_model_temp, df_test)
rmse_temp <- sqrt(mean((df_test$inflacion - pred_temp)^2))
# Guardar el RMSE
df_rmse <- rbind(df_rmse, data.frame(ntree = nt, rmse = rmse_temp))
}
head(df_rmse %>% arrange(rmse))
# Obtener el ntree con el menor RMSE
arboles_optimos <- 35
cat("Número óptimo de árboles:", arboles_optimos, "\n")
# Ajustar el modelo con el número óptimo de árboles
rf_model_opt <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi,
data = df_train,
ntree = arboles_optimos,
mtry = 3)
# Resumen del modelo
print(rf_model_opt)
# Importancia de las variables usando IncNodePurity
importancia <- importance(rf_model_opt)
importancia_df <- data.frame(Variable = rownames(importancia),
Importancia = importancia[, "IncNodePurity"])
# Ordena las variables por importancia
importancia_df <- importancia_df[order(importancia_df$Importancia, decreasing = TRUE),]
plot <- ggplot(importancia_df, aes(x = reorder(Variable, Importancia), y = Importancia)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Importancia de las Variables",
x = "",
y = "Incremento en Pureza del Nodo")
ggplotly(plot)
# Predecir la inflación en el conjunto de prueba
predicciones_opt <- predict(rf_model_opt, df_test)
# Predecir la inflación en el conjunto de prueba
predicciones_opt <- predict(rf_model_opt, df_test)
# Evaluar el rendimiento del modelo optimizado (ejemplo con RMSE)
rmse_opt <-sqrt(mean((df_test$inflacion - predicciones_opt)^2))
cat("RMSE del modelo optimizado:", rmse_opt, "\n")
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, max(df_pred$Real)) +
xlim(0, max(df_pred$Real)) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
ggplotly(plot)
# Crear un gráfico de dispersión de los valores reales vs. las predicciones
df_pred <- data.frame(Real = df_test$inflacion, Predicción = predicciones_opt)
plot <- ggplot(df_pred, aes(x = Real, y = Predicción)) +
geom_point(color = "#4400a4") +
geom_abline(intercept = 0, slope = 1, color = "red") +
ylim(0, max(df_pred$Real)) +
xlim(0, max(df_pred$Real)) +
labs(title = "Valores Reales vs. Predicciones",
x = "Real",
y = "Predicción")
# Convertir a objeto plotly y agrgarle el rmse a los puntos
plot <- ggplotly(plot) %>%
layout(annotations = list(x = 0.5, y = 0.9, text = paste("RMSE:", round(rmse_opt, 2), collapse = " "), showarrow = FALSE))
plot
