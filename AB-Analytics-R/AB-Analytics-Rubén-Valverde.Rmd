---
title: "Impacto de la inflaci√≥n en la Macroeconomia"
author: "Rub√©n Valverde Romero"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    fig_width: 12 
    fig_height: 6   
    css: style.css
    theme: cosmo
    toc: true
    toc_float:
      collapsed: true
---

## Introducci√≥n {#introduccion}

En este informe se tiene como objetivo analizar que relaci√≥n tiene la inflaci√≥n con el crecimiento de la productividad, recaudaci√≥n estatal
y la corrupci√≥n que perciben los ciudadanos.

### Origen de los Datos {#obtencion-de-los-datos}

Los datos utilizados en este an√°lisis provienen de 2 fuentes:

-   **Inflaci√≥n**: Los datos de inflaci√≥n anual por pa√≠s y regi√≥n se obtuvieron del [Fondo Monetario
    Internacional](https://www.imf.org/external/datamapper/NGDP_RPCH@WEO/OEMDC/ADVEC/WEOWORLD "Fondo Monetario Internacional").

-   **PIB**: Los datos que tratan sobre producto interior bruto provienen del [Fondo Monetario
    Internacional](https://www.imf.org/external/datamapper/NGDPD@WEO/WEOWORLD "Fondo Monetario Internacional").

-   **Ingreso Fiscal**: Los datos de presi√≥n fiscal provienen del [Fondo Monetario
    Internacional](https://www.imf.org/external/datamapper/rev@FPP/USA/FRA/JPN/GBR/SWE/ESP/ITA/ZAF/IND/URY/VEN "Fondo Monetario Internacional").

-   **PIB per Capita**: Los datos de PIB per capita provienen del [Fondo Monetario
    Internacional](https://www.imf.org/external/datamapper/NGDPDPC@WEO/OEMDC/ADVEC/WEOWORLD "Fondo Monetario Internacional").

-   **√çndice de Percepci√≥n de Corrupci√≥n (CPI)**: Los datos del CPI se obtuvieron de
    [Transparency.org](https://www.transparency.org/en/ "Transparency.org"), una organizaci√≥n sin fines de lucro que publica anualmente el
    √≠ndice de percepci√≥n de corrupci√≥n.

## Extracci√≥n de Datos {#extraccion-de-datos}

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(RColorBrewer)
library(ggcorrplot)
library(readxl)
library(plotly)
library(scales)
library(reshape2)
library(corrplot)
library(stringdist)
library(randomForest)
library(caret)
```

### Importaci√≥n de Datos del FMI {#importacion-de-datos}

Inflaci√≥n:

```{r message=FALSE, warning=FALSE}
inflacion <- read_excel("datasets/imf-dm-export-inflacion.xlsx")
head(inflacion[0:2])
```

Producto interior bruto (PIB):

```{r message=FALSE, warning=FALSE}
pib <- read_excel("datasets/imf-dm-export-pib.xls")
head(pib[0:2])
```

Ingreso fiscal:

```{r message=FALSE, warning=FALSE}
ingreso_fiscal <- read_excel("datasets/imf-dm-export-presion-fiscal.xls")
head(ingreso_fiscal[0:2])
```

PIB per capita:

```{r message=FALSE, warning=FALSE}
pib_per_capita <- read_excel("datasets/imf-dm-export-pib-per-capita.xls")
head(pib_per_capita[0:2])
```

### Funci√≥n para formatear los df del FMI {#funcion-fmi}

Procesa y formatea los datos obtenidos del Fondo Monetario Internacional.

**Argumentos:**

-   `df`: Dataframe del FMI

-   `valor`: string con el que renombrar la columna al pivotar

**Devuelve:**

El dataframe formateado de ancho a largo con 3 columnas, el nombre de las columnas originales se meten en la nueva columna "a√±o" y sus
valores correspondientes en "valor"

**Pasos:**

1.  Remplazar valores "no data" por nulos
2.  Eliminar todos los nulos
3.  Renombrar la primera columna a pa√≠s
4.  Meter en un array los a√±os que tenga el DataFrame de turno
5.  Convertir columnas a formato num√©rico para evitar posibles errores
6.  Obtener el nombre del df para utilizarlo como nombre de columna
7.  Transformar el DataFrame del formato ancho al formato largo con el nombre de columna proporcionado
8.  Convertir las dos columnas resultantes a num√©rico
9.  Mostrar primeros registros y resumen de los datos
10. Devolver el dataframe transformado

```{r message=FALSE, warning=FALSE}
formatear_fmi <- function(df, valor) {
  
  # Contar los datos nulos
  df <- df %>% replace(df == "no data", NA)
  print(paste("Total Nulos:", sum(is.na(df))))
  
  # Eliminar los datos nulos
  df <- df %>% drop_na()
  
  # Seleccionar las columnas de los a√±os
  a√±os <- colnames(df)[-1]
  
  # Cambiar el nombre de la columna de pa√≠s
  colnames(df)[1] <- "pais"
  
  # Convertir las columnas a valores num√©ricos
  df <- df %>% mutate_at(vars(-pais), as.numeric)
    
  # Transformar el DataFrame de formato ancho a formato largo
  df <- df %>% pivot_longer(cols = all_of(a√±os)
                            , names_to ="a√±o", 
                            values_to = valor) %>%
               mutate(across(c(valor, a√±o), as.numeric))

  # Mostrar los primeros registros y el resumen de los datos
  print("Primeros Registros:")
  print(head(df))
  
  print("Resumen de los Datos:")
  print(summary(df))
  
  return(df)
}

```

### Union de los Datos del FMI {#pib}

Se ejecuta la funci√≥n anterior con los datos de inflaci√≥n, PIB, ingreso fiscal y PIB per capita.

Inflaci√≥n:

```{r message=FALSE, warning=FALSE}
inflacion <- formatear_fmi(inflacion, "inflacion")
```

Producto interior bruto (PIB):

```{r message=FALSE, warning=FALSE}
pib <- formatear_fmi(pib, "pib")
```

Ingreso fiscal:

```{r message=FALSE, warning=FALSE}
ingreso_fiscal <- formatear_fmi(ingreso_fiscal, "ingreso_fiscal")
```

PIB per capita:

```{r message=FALSE, warning=FALSE}
pib_per_capita <- formatear_fmi(pib_per_capita, "pib_per_capita")
```

Se unen los datos del FMI en un solo DataFrame en los pa√≠ses coincidentes por a√±o.

```{r message=FALSE, warning=FALSE}
fmi <- pib %>%
    full_join(ingreso_fiscal, by = c("pais", "a√±o")) %>%
    full_join(pib_per_capita, by = c("pais", "a√±o")) %>%
    full_join(inflacion, by = c("pais", "a√±o"))

```

Se filtran los datos a partir del a√±o 1995 porque es el a√±o en el que se tienen datos de CPI.

```{r message=FALSE, warning=FALSE}
fmi <- fmi %>% filter(a√±o >= 1995 & a√±o <= 2023)
```

### Importaci√≥n de Datos del CPI {#importacion-de-datos-cpi}

#### Informaci√≥n de los formatos originales

En total se tienen 18 archivos:

-   1995-2011: Se componen de 17 CSV (1 por a√±o), salvo el de 1999 todos tienen las columnas en el mismo orden (se solucion√≥ modificando el
    csv directamente)

-   2012-2023: Una hoja de c√°lculo con el formato deseado (pa√≠s, a√±o, valor)

#### Bucle para unir y formatear los CSV

Primero importo los datos del CPI de 2011 ya que es el a√±o con m√°s pa√≠ses de 1995 a 2011.

```{r message=FALSE, warning=FALSE}
cpi <- read.csv("datasets/cpi/CPI-Archive-2011.csv")[c(1,4)] 
```

La idea es tener un a√±o de referencia al que ir uniendo el resto de a√±os hasta 1995, dado que 2011 es el a√±o con m√°s pa√≠ses, es m√°s r√°pido

Dado que si se une un df con otro y **no** hay coincidencias en los nombres de las columnas **no** se crean columnas con sufijos, esto
implicar√≠a que no habr√≠a una columna "score2010" sino "score". Al final o cambio el nombre del a√±o 2011 o 2010.

Conclusi√≥n: <button onclick="document.getElementById(&#39;audio&#39;).play()"> üîä </button>

<audio id="audio" src="audio/In The End -Linkin Park.mp3">

</audio>

```{r}
colnames(cpi) <- c("pais","score")
```

Este bucle une los datos de los a√±os 2011 a 1995.\
**Pasos:**

1.  Iniciar un bucle que recorre los a√±os de 2010 a 1995.

2.  Importar los datos del a√±o correspondiente.

3.  Cambiar el nombre de la primera columna a "pa√≠s".

4.  Unir los datos del a√±o df principal utilizando el a√±o como\
    sufijo.

```{r message=FALSE, warning=FALSE}
for (a√±o in 2010:1995) {

  # Importar los datos del CPI
  cpi_a√±o <- read.csv(paste0("datasets/cpi/CPI-Archive-",a√±o,".csv"))[c(1,4)]
  
  # Cambiar el nombre de la columna de pa√≠s
  colnames(cpi_a√±o)[1] <- "pais"
  
  # Unir los datos del CPI
  cpi <- cpi %>%
    left_join(cpi_a√±o, by = "pais", suffix = c("", a√±o))
}
```

```{r message=FALSE, warning=FALSE}
colnames(cpi)[2] <- "score2011"
```

Convertir las columnas a num√©rico para evitar error al pivotar:

```{r message=FALSE, warning=FALSE}

# Convertir las columnas a num√©rico por error al pivotar
cpi <- cpi %>% mutate(across(starts_with("score"), as.numeric))
```

Se transforma el DataFrame de formato ancho a largo.

```{r message=FALSE, warning=FALSE}
cpi <- cpi %>% pivot_longer( cols = starts_with("score"), names_to = "a√±o", names_prefix = "score", values_to = "cpi") %>% 
       mutate(a√±o = as.numeric(a√±o))
```

Se ajusta la escala del CPI para que concuerde con los a√±os posteriores.

```{r message=FALSE, warning=FALSE}
# Ajustar la escala
cpi$cpi <- cpi$cpi * 10
```

Importar los datos de 2012 a 2023.

```{r message=FALSE, warning=FALSE}
# Importar el resto de a√±os
cpi_2012_2022 <- read_excel("datasets/cpi/CPI-Archive-2012-2023.xlsx")[c(1,3,5)] 
```

Cambiar el nombre de las columnas y pasar a num√©rico.

```{r message=FALSE, warning=FALSE}
# Cambiar el nombre de las columnas
colnames(cpi_2012_2022) <- c("pais","a√±o", "cpi")

# Pasar a num√©rico
cpi_2012_2022 <- cpi_2012_2022 %>% mutate(cpi = as.numeric(cpi),
                                          a√±o = as.numeric(a√±o))
```

Unir los datos del CPI verticalmente.

```{r message=FALSE, warning=FALSE}
# Unir los datos del CPI verticalmente
cpi <- rbind(cpi, cpi_2012_2022)
```

### Unir los Datos del FMI con el CPI {#unir-datos-cpi}

Mapear los nombres de paises con un alto porcentaje de error pero que son correctos.

```{r message=FALSE, warning=FALSE}
fmi$pais <- recode(fmi$pais,
                   "Korea, Republic of" = "Korea (South)",
                   "China, People's Republic of" = "China",
                   "Congo, Dem. Rep. of the" = "Congo",
                   "Taiwan Province of China" = "Taiwan",
                   "Australia and New Zealand" = "Australia",
                   "S√£o Tom√© and Pr√≠ncipe" = "Sao Tome and Principe",
                   "Gambia, The" = "Gambia",
                   "Bahamas, The" = "Bahamas",
                   "Congo, Republic of" = "Congo Republic",
                   "Hong Kong SAR" = "Hong Kong")
```

Calcular la similitud entre los nombres de los pa√≠ses del FMI y el CPI.

Para ello utilizare el algoritmo Jaro-Winkler, se comparan todos con todos y se escoge para cada nombre el que tenga mejor puntuaci√≥n.

#### Explicaci√≥n Jaro-Winkler

Se basa en la coincidencia, trasposici√≥n y una penalizaci√≥n para las diferencias en las primeras letras de las cadenas.

1.  **Similitud de Jaro**:

$$ S_{j} = \frac{1}{3} \left( \frac{m}{|s_1|} + \frac{m}{|s_2|} + \frac{m - t}{m} \right) $$

Donde: - $s_1$ y $s_2$ ‚Üí cadenas de texto que se comparan. - $|s_1|$ y $|s_2|$ ‚Üí longitudes de las cadenas. - $m$ ‚Üí n√∫mero de caracteres
coincidentes entre las dos cadenas. - $t$ ‚Üí n√∫mero de trasposiciones, lo contrario a $m$

2.  **Similitud de Jaro-Winkler**:

$$ S_{jw} =S_{j} + \ell \cdot p \cdot (1 - S_j) $$

Donde:

1.  $S_{j}$ ‚Üí Similitud de Jaro.
2.  $\ell$ ‚Üí Longitud del prefijo com√∫n al inicio de las cadenas (m√°ximo 4 caracteres).
3.  $p$ ‚Üí Escalador de peso para el prefijo (normalmente $p = 0.1$).

El resultado de $S_{jw}$ es un valor entre 0 y 1, donde 1 indica una similitud perfecta y 0 indica ninguna similitud.

##### Ejemplo

**¬øQue palabra es m√°s cercana a "Corea": "Korea" o "Correa"?**

1.  C√°lculo de $S_j$:

    1.  Coincidencias ($m$): Los caracteres coincidentes son: $o, r, e, a$ (4 caracteres).

    2.  Longitud de las cadenas ($|s_1|, |s_2|$): Ambas tienen longitud 5.

    3.  Transposiciones ($t$): Hay una transposici√≥n entre $C$ y $K$. Esto equivale a $t = 1/2 = 0.5$.

Sustituyendo en la f√≥rmula de $S_j$:
$$ S_j = \frac{1}{3} \left( \frac{4}{5} + \frac{4}{5} + \frac{4 - 0.5}{4} \right) = \frac{1}{3} \left( 0.8 + 0.8 + 0.875 \right) = 0.825 $$

2.  **C√°lculo de** $S_{jw}$:

    1.  Prefijo com√∫n ($\ell$): El prefijo com√∫n es vac√≠o ($\ell = 0$).

    2.  Factor de prefijo ($p$): $p = 0.1$.

$$ S_{jw} = S_j + \ell \cdot p \cdot (1 - S_j) = 0.825 + 0 \cdot 0.1 \cdot (1 - 0.825) = 0.825 $$

```{r message=FALSE, warning=FALSE}
# Calcula la distancia de similitud entre los nombres de los pa√≠ses
distancias <- stringdistmatrix(fmi$pais, cpi$pais, method = "jw")
```

Obtener los √≠ndices de los string m√°s similares.\
*Nota: El resultado que devuelve R es 1 -* $S_{jw}$, por eso se selecciona el m√≠nimo y no el m√°ximo.

```{r message=FALSE, warning=FALSE}
indices <- apply(distancias, 1, which.min)
```

En base a los indices anteriores se obtienen los nombres equivalentes.

```{r message=FALSE, warning=FALSE}
nombres_equivalentes <- cpi$pais[indices]
```

En vez de seleccionar el indice, me quedo con el valor y lo paso a porcentaje.

```{r message=FALSE, warning=FALSE}
# Calcula el porcentaje de error estimado
porcentaje_error <- apply(distancias, 1, min)
porcentaje_error <- porcentaje_error * 100
```

A√±ado el porcentaje de error y los nombres equivalentes al df, luego muestro los pa√≠ses y sus equivalentes ordenados por porcentaje de
error. En base a esta tabla se realizaron los cambios de nombres anteriores.

```{r message=FALSE, warning=FALSE}
# A√±adir el porcentaje de error estimado al dataframe original
fmi <- fmi %>%
  mutate(porcentaje_error = porcentaje_error,
         nombre_eq = nombres_equivalentes)
fmi %>% select(pais, nombre_eq, porcentaje_error) %>%  group_by(pais) %>% slice(1) %>% arrange(desc(porcentaje_error)) 
```

Elimino las filas con un porcentaje superior a 0.

```{r message=FALSE, warning=FALSE}
fmi <- fmi %>% ungroup() %>% filter(porcentaje_error == 0)
```

Sustituyo los nombres por su equivalente y me quedo con las columnas de inter√©s.

```{r message=FALSE, warning=FALSE}
fmi$pais <- fmi$nombre_eq
fmi <- fmi %>% select(-nombre_eq, -porcentaje_error) %>% 
  mutate(a√±o = as.numeric(a√±o))
```

Unir los Dataframe finales del CPI y FMI

```{r message=FALSE, warning=FALSE}
df <- cpi %>%
  full_join(fmi, by = c("pais", "a√±o"))

df <- df %>% arrange(pais, a√±o) 
```

Elimino las filas que no tengan al menos 2 variables sin nulos, no se puede realizar una correlaci√≥n con 1 sola variable.

```{r message=FALSE, warning=FALSE}
df <- df[rowSums(is.na(df)) < 4, ]
```

Muestro su resumen y los primeros registros.

```{r message=FALSE, warning=FALSE}
summary(df)
head(df)
```

### Descripci√≥n de los datos del DataFrame Final {#descripcion-del-dataframe-transformado}

1.  **Pa√≠s**:
    -   Tipo de dato: Car√°cter.
    -   Descripci√≥n: Nombre del pa√≠s.
2.  **A√±o**:
    -   Tipo de dato: Num√©rico.
    -   Descripci√≥n: A√±o al que pertenecen los datos.
3.  **Puntuaci√≥n de Corrupci√≥n (CPI)**:
    -   Tipo de dato: Num√©rico.
    -   Descripci√≥n: Representa la percepci√≥n de corrupci√≥n en el sector p√∫blico de un pa√≠s en una escala de 0 a 100, donde 0 indica una
        alta percepci√≥n de corrupci√≥n y 100 indica una baja percepci√≥n de corrupci√≥n.
4.  **Inflaci√≥n**:
    -   Tipo de dato: Num√©rico.
    -   Descripci√≥n: Representa la perdida de poder adquisitivo de los ciudadanos.
5.  **PIB:**
    -   Tipo de dato: Num√©rico.
    -   Descripci√≥n: Representa el valor total de todos los bienes y servicios producidos en un pa√≠s en un a√±o determinado.
6.  **PIB per Capita**:
    -   Tipo de dato: Num√©rico.
    -   Descripci√≥n: Representa el valor total de todos los bienes y servicios producidos en un pa√≠s en un a√±o determinado dividido por la
        poblaci√≥n total del pa√≠s.
7.  **Ingresos_fiscales**:
    -   Tipo de dato: Num√©rico.
    -   Descripci√≥n: Representa la cantidad total de ingresos recaudados por el estado a trav√©s de impuestos, expresado en % del PIB. No
        tiene en cuenta el endeudamiento.

## An√°lisis Exploratorio de Datos {#eda}

### N√∫mero de paises por a√±o {#paises-por-a√±o}

Agrego los datos por a√±o y creo el gr√°fico de barras.

```{r}
# Pasar el dataframe a formato largo
df_long <- df %>% 
  select(-pais) %>%
  pivot_longer(cols = -a√±o, names_to = "variable", values_to = "valor") %>%
  group_by(a√±o, variable) %>%
  summarize(n_nulos = sum(is.na(valor)), .groups = "drop")

# Crear el gr√°fico con ggplot2
nulos_a√±o_plot <- ggplot(df_long, aes(x = a√±o, y = n_nulos, fill = variable )) +
  geom_bar(stat = "identity", width = 0.9, color="#aaa") +
  facet_wrap(~variable, scales = "free") +
  labs(
    title = "Cantidad de Nulos por A√±o y Variable",
    x = "A√±o",
    y = "Cantidad de Nulos"
  ) +
  theme(legend.position = "none",
        panel.spacing.x = unit(2, "lines"),
        panel.spacing.y = unit(4, "lines"))

ggplotly(nulos_a√±o_plot)
```

### Visualizaci√≥n de los Datos en el tiempo {#visualizacion-de-los-datos}

Se agrupan los datos por a√±o y se calcula la media de todas las variables, mediana para el caso de la inflaci√≥n debido a valores extremos.

```{r fig.height= 6}
df_avg <- df %>%
  group_by(a√±o) %>%
  summarise(
    cpi = mean(cpi, na.rm = TRUE),
    inflacion = median(inflacion, na.rm = TRUE),
    pib = mean(pib, na.rm = TRUE),
    pib_per_capita = mean(pib_per_capita, na.rm = TRUE),
    ingreso_fiscal = mean(ingreso_fiscal, na.rm = TRUE), 
    .groups = "drop"
  )
```

Se transforman los datos a formato largo para poder visualizarlos en un gr√°fico. Se quita la columna a√±o y el nombre de las variables pasa a
ser la columna "variable" y su contenido en "valor".

```{r message=FALSE, warning=FALSE}
df_avg_largo <- df_avg %>%
  pivot_longer(cols = -a√±o, names_to = "variable", values_to = "valor")

```

Crea varios lineplots interactivos, uno para cada variable, representando c√≥mo cambian a lo largo del tiempo. Cada l√≠nea tiene puntos
conectados para mostrar los valores individuales. El gr√°fico se divide en paneles para comparar las tendencias entre diferentes variables,
se aumenta el margen entre los gr√°ficos para impedir que se solapen.

```{r message=FALSE, warning=FALSE}
# Crear el gr√°fico
plot <- ggplot(df_avg_largo, aes(x = a√±o, y = valor, color = variable)) +
  geom_line() +
  geom_point(size = 2) +
  facet_wrap(~variable, scales = "free") +
  labs(
    title = "Evoluci√≥n de las Variables Num√©ricas (1995-2022) ",
    x = "A√±o",
    y = ""
  ) +
  theme(legend.position = "none",
        panel.spacing.x = unit(2, "lines"),
        panel.spacing.y = unit(4, "lines"))

# Convertir a objeto plotly
ggplotly(plot)

```

### Visualizaci√≥n de las distribuciones {#visualizacion-distribuciones}

Algunas variables tienen un pico muy acusado como distribuci√≥n y las colas casi inexsistentes, por lo que se transforman a logaritmo base 2
para poder apreciar mejor la distribuci√≥n, concrertamente la inflaci√≥n, PIB, PIB per capita e ingreso fiscal.

```{r, warning=FALSE, message=FALSE, fig.height= 6}
# Seleccionar las columnas de inter√©s
df_correlacion <- df %>% select(-pais, -a√±o) %>%
                  mutate( inflacion = log2(inflacion),
                          pib = log2(pib),
                          pib_per_capita = log2(pib_per_capita),
                          ingreso_fiscal = log2(ingreso_fiscal)) %>%
                  mutate_all(~rescale(.))
```

Se transforman los datos a formato largo. En este caso no necesito ninguna columna adicional, por lo que utilizo la funci√≥n gather que es
m√°s sencilla.

```{r message=FALSE, warning=FALSE}
# Transformar el DataFrame de formato ancho a formato largo
df_correlacion_largo <-  df_correlacion %>% gather(variable, valor)
```

Mismo sistema que en el gr√°fico anterior, se crea un gr√°fico pero de densidad para cada variable.

```{r message=FALSE, warning=FALSE}
# Crear un gr√°fico de densidad para cada variable
plot <- ggplot(df_correlacion_largo, aes(x = valor, fill = variable)) +
  geom_density() +
  facet_wrap(~variable, scales = "free") +
  labs(x = "",
       y = "Densidad") +
  theme(legend.position = "none",
        panel.spacing.x = unit(1, "lines"),
        panel.spacing.y = unit(3, "lines"))

# Convertir a objeto plotly
ggplotly(plot)

```

### Visualizaci√≥n de la inflaci√≥n vs el resto de variables {#visualizacion-scatter}

Algunas variables tienen un pico muy acusado como distribuci√≥n y las colas casi inexsistentes, por lo que se transforman a logaritmo base 2
para poder apreciar mejor la distribuci√≥n, concretamente la inflaci√≥n, PIB, PIB per capita e ingreso fiscal.

```{r message=FALSE, warning=FALSE}
df_correlacion <- df %>% select(-pais, -a√±o) %>%
                         filter(inflacion < 75) %>%
                         mutate(pib = rescale(log10(pib)),
                                pib_per_capita = rescale(log10(pib_per_capita))) %>%
                         mutate_all(~rescale(.))
 
df_correlacion_largo <- df_correlacion %>%
                        pivot_longer(cols = -inflacion, names_to = "variable", values_to = "valor")

```

Mismo sistema que en el gr√°fico anterior, se crea un gr√°fico pero de densidad para cada variable.

```{r message=FALSE, warning=FALSE}
plot <- ggplot(df_correlacion_largo, aes(x = inflacion, y = valor)) +
  geom_bin2d(binwidth = c(0.015, 0.015)) +
  scale_fill_gradient(low = "#ada1ff", high = "#df0000") +
  labs(
    x = "",
    y = "") +
  ylim(0, 1) +
  xlim(0, 1) +
  facet_wrap(~variable, scales = "free") +
  labs(
    title = "Scatterplot de Inflaci√≥n vs Resto de Variables",
    x = "",
    y = "") +
  theme(legend.position = "none",
        panel.spacing.x = unit(2, "lines"),
        panel.spacing.y = unit(4, "lines"))

# Convertir a objeto plotly
ggplotly(plot)

```

## An√°lisis de Correlaci√≥n {#correlacion}

### Calculo de la matriz de correlaci√≥n

Quito las columnas de pa√≠s y a√±o para calcular la matriz de correlaci√≥n.

```{r Matriz de Correlaci√≥n, warning=FALSE}
df_correlacion <- df %>% select(-pais, -a√±o)
```

Meto el n√∫mero de columnas en una variable para crear matrices vac√≠as

```{r message=FALSE, warning=FALSE}
# Crear matrices vac√≠as para almacenar p-valores m√°s bajos, m√©todos y coeficientes de correlaci√≥n
n <- ncol(df_correlacion)
```

Array con los dos posibles m√©todos de correlaci√≥n.

```{r message=FALSE, warning=FALSE}
metodos <- c("spearman", "pearson")
```

Creo dos matrices vac√≠as, una para los p-valores y otra para los coeficientes de correlaci√≥n.

```{r message=FALSE, warning=FALSE}
p_metodo <- matrix(" ", n, n, dimnames = list(names(df_correlacion), names(df_correlacion)))
cor_matrix <- matrix(1, n, n, dimnames = list(names(df_correlacion), names(df_correlacion)))
```

Comparo en cada par que m√©todo tiene el p-valor m√°s bajo para seleccionarlo y calcular el coeficiente de correlaci√≥n.

**Pasos:**

1.  Creo dos bucles que recorren las variables formando los pares de variables.

2.  Asignar los nombres de las variables correspondientes a trav√©s de su posici√≥n en el array con los nombres de las variables.

3.  Calcula los p-valores para la prueba de correlaci√≥n entre las dos variables utilizando tanto el m√©todo de Pearson como el de Spearman.
    El resultado es un array con 2 p-valores.

4.  Selecciona el m√©todo con el p-valor m√°s bajo.

5.  Almacena ese p-valor.

6.  Calcula la correlaci√≥n con el m√©todo elegido.

7.  Almacena los resultados en 2 matrices cuyos indices son el nombre de las variables:

    1.  En la primera matriz almacena en la primera mitad elegido en el par y en la segunda mitad el p-valor redondeado conservando la
        notaci√≥n cient√≠fica.

    2.  En la segunda se almacenan en las dos mitades lo mismo, los coeficientes de correlaci√≥n.

```{r message=FALSE, warning=FALSE}
# Iterar sobre las combinaciones de pares de columnas
for (j in 1:(n-1)) {
  for (k in (j+1):n) {
    var1 <- names(df_correlacion)[j]
    var2 <- names(df_correlacion)[k]
    p_valores <- sapply(metodos, function(metodo) cor.test(df_correlacion[[var1]], df_correlacion[[var2]], method = metodo, use ="complete.obs")$p.value)
    
    # Identificar el p-valor m√°s bajo y el m√©todo correspondiente
    metodo_elegido <- metodos[which.min(p_valores)]
    p_valor_minimo <- min(p_valores)
    
    # Calcular el coeficiente de correlaci√≥n usando el m√©todo elegido
    correlacion <- cor(df[[var1]], df[[var2]], method = metodo_elegido, use ="complete.obs")
    
    # Almacenar el p-valor m√°s bajo, el m√©todo elegido y el coeficiente de correlaci√≥n
    p_metodo[var1, var2] <- metodo_elegido
    p_metodo[var2, var1] <- format(p_valor_minimo, digits = 2, scientific = TRUE)
    
    cor_matrix[var1, var2] <- correlacion
    cor_matrix[var2, var1] <- correlacion
  }
}
```

### Visualizaci√≥n de la matriz de p-valores y m√©todos

Almaceno el nombre de las variables en 2 columnas y en otra tercera su valor (m√©todo o p-valor)

```{r}
p_metodo_df <- melt(p_metodo, varnames = c("Variable1", "Variable2"), value.name = "Valor")
```

El gr√°fico es una matriz de colores donde cada celda representa el p-valor correspondiente al test de correlaci√≥n entre 2 variables y el
m√©todo utilizado.

Al introducir los m√©todos la escala de colores es discreta, lo que implica que tendr√≠a que asignarle un color a cada p-valor, dado todos los
p-valores est√°n muy por debajo de 0.05 asigno como color por defecto el verde clarito.

Las celdas intermedias no aportan informaci√≥n, he introducido como valor un espacio para poder pintarlas de un color que llame menos la
atenci√≥n que los de su alrededor, en este caso gris.

```{r message=FALSE, warning=FALSE}
# Crear la visualizaci√≥n
method_plot <- ggplot(data = p_metodo_df, aes(x = Variable1, y = Variable2, fill = Valor)) + 
  geom_tile(color = "black") +  
  geom_text(aes(label = Valor), 
            size = 4, 
            color = "black") + 
  scale_fill_manual(values = c("pearson" = "#e033ff", "spearman" = "#fdaf7a"," " = "#e9e9e9"),na.value = "#e0ffbf") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.line = element_line(color = "black"),
        panel.background = element_rect(fill = "#f9f9f9", color = NA),  
        plot.background = element_rect(fill = "#f9f9f9", color = NA),   
        legend.position = "none") +
  labs(title = "M√©todos de Correlaci√≥n Utilizados y sus P-Valores", 
       x = "", 
       y = "", 
       fill = "M√©todo")

method_plot <- ggplotly(method_plot) %>% 
               layout(autosize = TRUE, 
                     xaxis = list(autorange = TRUE))
method_plot
```

### Visualizaci√≥n de la matriz de correlaci√≥n

Creo un corrplot con la matriz de correlaciones generada en el bucle.

```{r fig.height = 9, fig.width = 12, message=FALSE, warning=FALSE}

corrplot <- ggcorrplot(cor_matrix, 
                       method = "circle",
                       type = "full",
                       lab = TRUE,
                       lab_size = 5) +
  scale_fill_gradient2(high ="#6400e4",mid="#f9e9e9",low = "#ff0000") +
  scale_size_continuous(range = c(8, 25)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.background = element_rect(fill = "#f9f9f9", color = NA),  
        plot.background = element_rect(fill = "#f9f9f9", color = NA),   
        axis.text = element_text(size = 2),
        legend.position = "none")

ggplotly(corrplot)
```

## Random Forest {#modelado}

```{r}
df_limpio <- df %>% select(-pais, -a√±o) %>% 
                    drop_na() %>%
                    filter(inflacion < quantile(inflacion, 0.9))
```

```{r}
# Dividir df_limpio en train y test
set.seed(2706)

train_index <- createDataPartition(1:nrow(df_limpio), p = .8, list = FALSE)

df_train <- df_limpio[train_index, ]
df_test <- df_limpio[-train_index, ]

# Contar valores
cat("N√∫mero de observaciones en el conjunto de entrenamiento:", nrow(df_train), "\n")
cat("N√∫mero de observaciones en el conjunto de prueba:", nrow(df_test), "\n")
# Resumen de los conjuntos de entrenamiento y prueba
summary(df_train)
summary(df_test)
```

```{r}
# Ajuste manual del n√∫mero √≥ptimo de √°rboles (ntree)
df_rmse <- data.frame(ntree = integer(), rmse = numeric())
ntree_values <- seq(5, 100, by = 1)
```

```{r}
for (nt in ntree_values) {
  rf_model_temp <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi, 
                                data = df_train, 
                                ntree = nt,
                                mtry = 3)
  
  pred_temp <- predict(rf_model_temp, df_test)
  rmse_temp <- sqrt(mean((df_test$inflacion - pred_temp)^2))
 
  # Guardar el RMSE
  df_rmse <- rbind(df_rmse, data.frame(ntree = nt, rmse = rmse_temp))
}
head(df_rmse %>% arrange(rmse))
```

```{r}
# Gr√°fico de MSE vs ntree
plot <- ggplot(df_rmse, aes(x = ntree, y = rmse)) +
        geom_line(color = "#4400a4") +
        geom_point(color = "#4400a4", size=0.6) +
        geom_area(fill = "#4400a4", alpha = 0.2) +
        labs(title = "RMSE vs N√∫mero de √Årboles",
             x = "N√∫mero de √Årboles",
             y = "RMSE") 
       
ggplotly(plot) 

```

```{r}
# Obtener el ntree con el menor RMSE
arboles_optimos <- 35
cat("N√∫mero √≥ptimo de √°rboles:", arboles_optimos, "\n")

# Ajustar el modelo con el n√∫mero √≥ptimo de √°rboles
rf_model_opt <- randomForest(inflacion ~ ingreso_fiscal + pib + pib_per_capita + cpi, 
                             data = df_train, 
                             ntree = arboles_optimos,
                             mtry = 3)
# Resumen del modelo
print(rf_model_opt)
```

```{r}

# Importancia de las variables usando IncNodePurity
importancia <- importance(rf_model_opt)
importancia_df <- data.frame(Variable = rownames(importancia), 
                             Importancia = importancia[, "IncNodePurity"])

# Ordena las variables por importancia
importancia_df <- importancia_df[order(importancia_df$Importancia, decreasing = TRUE),]

plot <- ggplot(importancia_df, aes(x = reorder(Variable, Importancia), y = Importancia)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Importancia de las Variables",
       x = "",
       y = "Incremento en Pureza del Nodo") 

ggplotly(plot)
```

```{r}
# Predecir la inflaci√≥n en el conjunto de prueba
predicciones_opt <- predict(rf_model_opt, df_test)
```

```{r}
# Evaluar el rendimiento del modelo optimizado (ejemplo con RMSE)
rmse_opt <-sqrt(mean((df_test$inflacion - predicciones_opt)^2))

cat("RMSE del modelo optimizado:", rmse_opt, "\n")

```

```{r}
# Crear un gr√°fico de dispersi√≥n de los valores reales vs. las predicciones

df_pred <- data.frame(Real = df_test$inflacion, Predicci√≥n = predicciones_opt)

plot <- ggplot(df_pred, aes(x = Real, y = Predicci√≥n)) +
  geom_point(color = "#4400a4") +
  geom_abline(intercept = 0, slope = 1, color = "red") +
  ylim(0, max(df_pred$Real)) +
  xlim(0, max(df_pred$Real)) +
  labs(title = "Valores Reales vs. Predicciones",
       x = "Real",
       y = "Predicci√≥n")

ggplotly(plot) 

```